{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9bab1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:04.229962Z",
     "iopub.status.busy": "2023-07-09T18:05:04.228852Z",
     "iopub.status.idle": "2023-07-09T18:05:04.234320Z",
     "shell.execute_reply": "2023-07-09T18:05:04.233452Z"
    },
    "papermill": {
     "duration": 0.017388,
     "end_time": "2023-07-09T18:05:04.238846",
     "exception": false,
     "start_time": "2023-07-09T18:05:04.221458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2b79f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:04.249983Z",
     "iopub.status.busy": "2023-07-09T18:05:04.249648Z",
     "iopub.status.idle": "2023-07-09T18:05:10.066525Z",
     "shell.execute_reply": "2023-07-09T18:05:10.065466Z"
    },
    "papermill": {
     "duration": 5.825563,
     "end_time": "2023-07-09T18:05:10.069451",
     "exception": false,
     "start_time": "2023-07-09T18:05:04.243888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.linalg import svdvals\n",
    "\n",
    "import numpy as np\n",
    "#import powerlaw\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from torch.nn.utils import prune as prune\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "#import kneed as kneed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7eabc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:10.082639Z",
     "iopub.status.busy": "2023-07-09T18:05:10.081450Z",
     "iopub.status.idle": "2023-07-09T18:05:10.092751Z",
     "shell.execute_reply": "2023-07-09T18:05:10.091803Z"
    },
    "papermill": {
     "duration": 0.019738,
     "end_time": "2023-07-09T18:05:10.094862",
     "exception": false,
     "start_time": "2023-07-09T18:05:10.075124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    timings = []\n",
    "    #GPU-WARM-UP\n",
    "    i=0\n",
    "    for data in test_loader:\n",
    "        if(i>1000):\n",
    "            break\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        _ = model(images)\n",
    "        i += 1\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            starter.record()\n",
    "            outputs = model(images)\n",
    "            ender.record()\n",
    "            \n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings.append(curr_time)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test images: '+str(100 * correct / total))\n",
    "    \n",
    "    tot = np.sum(timings)\n",
    "    mean_syn_per_batch = np.sum(timings) / len(timings)\n",
    "    std_syn_per_batch = np.std(timings)\n",
    "    print(\"Total inference time for test data: \"+str(tot))\n",
    "    print(\"Mean inference time per test batch: \"+str(mean_syn_per_batch))\n",
    "    print(\"Standard deviation of inference times per test batch: \"+str(std_syn_per_batch))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5998605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:10.106103Z",
     "iopub.status.busy": "2023-07-09T18:05:10.105829Z",
     "iopub.status.idle": "2023-07-09T18:05:15.379581Z",
     "shell.execute_reply": "2023-07-09T18:05:15.378563Z"
    },
    "papermill": {
     "duration": 5.28207,
     "end_time": "2023-07-09T18:05:15.381996",
     "exception": false,
     "start_time": "2023-07-09T18:05:10.099926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/vgg/cifar10_vgg16_bn-6ee7ea24.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_vgg16_bn-6ee7ea24.pt\n",
      "100%|██████████| 58.3M/58.3M [00:00<00:00, 157MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "\n",
    "\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "torch.save(model, \"./unpruned_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00f1481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:15.397375Z",
     "iopub.status.busy": "2023-07-09T18:05:15.396380Z",
     "iopub.status.idle": "2023-07-09T18:05:15.403244Z",
     "shell.execute_reply": "2023-07-09T18:05:15.402329Z"
    },
    "papermill": {
     "duration": 0.01628,
     "end_time": "2023-07-09T18:05:15.405462",
     "exception": false,
     "start_time": "2023-07-09T18:05:15.389182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace=True)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace=True)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace=True)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU(inplace=True)\n",
      "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (32): ReLU(inplace=True)\n",
      "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (36): ReLU(inplace=True)\n",
      "  (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (39): ReLU(inplace=True)\n",
      "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (42): ReLU(inplace=True)\n",
      "  (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(model.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f211d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:15.419646Z",
     "iopub.status.busy": "2023-07-09T18:05:15.419353Z",
     "iopub.status.idle": "2023-07-09T18:05:20.819549Z",
     "shell.execute_reply": "2023-07-09T18:05:20.818638Z"
    },
    "papermill": {
     "duration": 5.410034,
     "end_time": "2023-07-09T18:05:20.821938",
     "exception": false,
     "start_time": "2023-07-09T18:05:15.411904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:01<00:00, 90027702.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transform = transforms.Compose([\n",
    "                                 transforms.Pad(4),\n",
    "                                 transforms.RandomCrop(32),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                             ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                             ])\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10('./datasets', train=True, \n",
    "                                         download=True, transform=train_transform)\n",
    "test_set = torchvision.datasets.CIFAR10('./datasets', train=False, \n",
    "                                        download=True, transform=test_transform)\n",
    "# Number of subprocesses to use for data loading\n",
    "num_workers = 1\n",
    "# How many samples per batch to load\n",
    "batch_size = 1\n",
    "# Percentage of training set to use as validation\n",
    "valid_size = 0.5\n",
    "\n",
    "num_test = len(test_set)\n",
    "indices = list(range(num_test))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_test))\n",
    "test_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# Define samplers for obtaining training and validation batches\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "# Prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
    "                                           num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(test_set, batch_size= 1, sampler=valid_sampler, \n",
    "                                           num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=2048, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a62384b",
   "metadata": {
    "papermill": {
     "duration": 0.009174,
     "end_time": "2023-07-09T18:05:20.839396",
     "exception": false,
     "start_time": "2023-07-09T18:05:20.830222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Testing the unpruned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b308e2af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:20.859869Z",
     "iopub.status.busy": "2023-07-09T18:05:20.859538Z",
     "iopub.status.idle": "2023-07-09T18:05:30.981181Z",
     "shell.execute_reply": "2023-07-09T18:05:30.980007Z"
    },
    "papermill": {
     "duration": 10.13444,
     "end_time": "2023-07-09T18:05:30.984509",
     "exception": false,
     "start_time": "2023-07-09T18:05:20.850069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 93.92\n",
      "Total inference time for test data: 616.8562927246094\n",
      "Mean inference time per test batch: 205.61876424153647\n",
      "Standard deviation of inference times per test batch: 65.96001123137506\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d01133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:31.015101Z",
     "iopub.status.busy": "2023-07-09T18:05:31.013789Z",
     "iopub.status.idle": "2023-07-09T18:05:31.092183Z",
     "shell.execute_reply": "2023-07-09T18:05:31.090346Z"
    },
    "papermill": {
     "duration": 0.096236,
     "end_time": "2023-07-09T18:05:31.095541",
     "exception": false,
     "start_time": "2023-07-09T18:05:30.999305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59c67a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:31.126479Z",
     "iopub.status.busy": "2023-07-09T18:05:31.126098Z",
     "iopub.status.idle": "2023-07-09T18:05:31.136126Z",
     "shell.execute_reply": "2023-07-09T18:05:31.135304Z"
    },
    "papermill": {
     "duration": 0.026647,
     "end_time": "2023-07-09T18:05:31.138652",
     "exception": false,
     "start_time": "2023-07-09T18:05:31.112005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ten2mat(tensor):\n",
    "    r,c,ch,f = tensor.shape\n",
    "    new_dim = [c,r*ch*f]\n",
    "    return np.reshape(tensor, new_dim)\n",
    "\n",
    "def eff_rank(matrix):\n",
    "    frob = np.linalg.norm(matrix, 'fro')\n",
    "    svals = svdvals(matrix)\n",
    "    S = max(svals)\n",
    "    r = frob/S\n",
    "    return (r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6264da1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:31.163688Z",
     "iopub.status.busy": "2023-07-09T18:05:31.163344Z",
     "iopub.status.idle": "2023-07-09T18:05:31.228989Z",
     "shell.execute_reply": "2023-07-09T18:05:31.228142Z"
    },
    "papermill": {
     "duration": 0.081469,
     "end_time": "2023-07-09T18:05:31.231568",
     "exception": false,
     "start_time": "2023-07-09T18:05:31.150099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#utility functions\n",
    "\n",
    "\n",
    "#reshape weight/feature tensor into a matrix\n",
    "def ten2mat(tensor):\n",
    "    r,c,ch,f = tensor.shape\n",
    "    new_dim = [c,r*ch*f]\n",
    "    return np.reshape(tensor, new_dim)\n",
    "################################################################################################################\n",
    "#Compute stable rank\n",
    "def eff_rank(matrix):\n",
    "    frob = np.linalg.norm(matrix, 'fro')\n",
    "    svals = svdvals(matrix)\n",
    "    S = max(svals)\n",
    "    r = frob/S\n",
    "    return (r)\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "# a dict to store the activations\n",
    "activation = {}\n",
    "def getActivation(name):\n",
    "  # the hook signature\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "#Function to get conv+bn feature means\n",
    "def get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter):\n",
    "    \n",
    "    activation = {}\n",
    "    def getActivation(name):\n",
    "      # the hook signature\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    mat_features_list_conv = [ [] ]*(nc*num_classes)\n",
    "    mat_features_list_bn = [ [] ]*(nc*num_classes)\n",
    "\n",
    "    count = np.zeros((nc*num_classes))\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        \n",
    "        try:\n",
    "            image,label = next(dataiter)\n",
    "        except StopIteration:\n",
    "            dataiter = iter(train_loader)\n",
    "            image,label = next(dataiter)\n",
    "        \n",
    "        \n",
    "        l2 =label.detach().numpy()\n",
    "        l2 = l2[0]\n",
    "        #print(l2)\n",
    "        for j in range(nc):#range(len(conv_dict)):\n",
    "            activation = {}\n",
    "            z1 = conv_dict[j]\n",
    "            z2 = z1 + 1\n",
    "\n",
    "            #print(z1,z2)\n",
    "            h1 = model.features[z1].register_forward_hook(getActivation('conv2d'))\n",
    "            h2 = model.features[z2].register_forward_hook(getActivation('bn'))\n",
    "\n",
    "            output = model(image.to(device))\n",
    "\n",
    "            Xx1 = activation['conv2d']\n",
    "            Xx2 = activation['bn']\n",
    "\n",
    "            Xx1 = Xx1.to(device = 'cpu')\n",
    "            Xx2 = Xx2.to(device = 'cpu')\n",
    "\n",
    "            Xx01 = Xx1.detach().numpy()\n",
    "            Xx02 = Xx2.detach().numpy()\n",
    "\n",
    "            temp_mat1 = ten2mat(Xx01)\n",
    "            temp_mat2 = ten2mat(Xx02)\n",
    "\n",
    "            temp_idx = int(num_classes*j + l2)\n",
    "\n",
    "            count[temp_idx]+=1\n",
    "            #print(i, np.linalg.norm(temp_mat1),np.linalg.norm(temp_mat2), np.linalg.norm(temp_mat3), l2, j, z1, temp_idx)\n",
    "\n",
    "            l31 = len(mat_features_list_conv[temp_idx])\n",
    "            l32 = len(mat_features_list_bn[temp_idx])\n",
    "\n",
    "            if l31 == 0:\n",
    "                mat_features_list_conv[temp_idx] = temp_mat1\n",
    "\n",
    "            else:\n",
    "                mat_features_list_conv[temp_idx] = mat_features_list_conv[temp_idx] + temp_mat1\n",
    "\n",
    "            if l32 == 0:\n",
    "                mat_features_list_bn[temp_idx] = temp_mat2\n",
    "\n",
    "            else:\n",
    "                mat_features_list_bn[temp_idx] = mat_features_list_bn[temp_idx] + temp_mat2\n",
    "\n",
    "\n",
    "            h1.remove()\n",
    "            h2.remove()\n",
    "       \n",
    "    for i in range(nc*num_classes):\n",
    "        mat_features_list_conv[i] = mat_features_list_conv[i] / count[i]\n",
    "        mat_features_list_bn[i] = mat_features_list_bn[i] / count[i]\n",
    "    \n",
    "    return mat_features_list_conv, mat_features_list_bn, count\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "\n",
    "#function to get differences between features\n",
    "\n",
    "def get_features_diff(nc, num_classes, mat_features_list, conv_dict):\n",
    "    \n",
    "    mat_diff_list = []\n",
    "    \n",
    "    ll = int(0.5 * num_classes * (num_classes - 1))\n",
    "\n",
    "\n",
    "    count_list = [ [[]]*ll ]*nc\n",
    "\n",
    "    for k in range(nc):\n",
    "        idx1 = 0\n",
    "        idx2 = num_classes*k\n",
    "        temp_list = [[]]*ll\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            for j in range(i+1,num_classes):\n",
    "                #print(idx1)\n",
    "                ti = i+idx2\n",
    "                tj = j+idx2\n",
    "                temp1 = mat_features_list[ti] - mat_features_list[tj]\n",
    "                \n",
    "                temp_list[idx1] = temp1\n",
    "\n",
    "                count_list[k][idx1]= (i,j)\n",
    "                idx1+=1\n",
    "        mat_diff_list.append([temp_list])\n",
    "\n",
    "        \n",
    "    return mat_diff_list\n",
    "\n",
    "#################################################################################################################\n",
    "        \n",
    "def get_min_list(nc, num_classes, mat_diff_list):\n",
    "    min_list = []\n",
    "    ll = int(0.5 * num_classes * (num_classes - 1))\n",
    "\n",
    "    for k in range(nc):\n",
    "        layer_list = mat_diff_list[k][0]\n",
    "\n",
    "\n",
    "        tempmat = layer_list[0]\n",
    "        \n",
    "        Y_conv = np.shape(tempmat)\n",
    "        num_channels = Y_conv[0]\n",
    "        #print(ll)\n",
    "        temp_min_list= [[]]*num_channels\n",
    "\n",
    "\n",
    "        for i in range(ll):\n",
    "            temp1  = layer_list[i]\n",
    "\n",
    "\n",
    "\n",
    "            temp1n = np.linalg.norm(temp1, axis=1)\n",
    "\n",
    "\n",
    "            for j in range(num_channels):           \n",
    "                if bool(temp_min_list[j]):\n",
    "                    if temp_min_list[j] > temp1n[j]:\n",
    "                        temp_min_list[j] = temp1n[j]                    \n",
    "                else:\n",
    "                    temp_min_list[j] = temp1n[j]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        min_list.append(temp_min_list)\n",
    "    return min_list\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    acc = 0  # TODO compute top1\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (idx, (x, t)) in enumerate(data_loader):\n",
    "            x = model.forward(x.to(device))\n",
    "            t = t.to(device)\n",
    "            _, indices = torch.max(x, 1)\n",
    "            correct_samples += torch.sum(indices == t)\n",
    "            total_samples += t.shape[0]\n",
    "\n",
    "    acc = float(correct_samples) / total_samples\n",
    "    return acc\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "def get_crit_vals(nc, min_list, crit_frac):\n",
    "    minlist = []\n",
    "    min_means = []\n",
    "    min_crit = []\n",
    "    for i in range(nc):\n",
    "        temp_list = min_list[i] / np.max(min_list[i])\n",
    "        mean = np.mean(temp_list)\n",
    "\n",
    "\n",
    "        #print(i,mean_conv, mean_bn)\n",
    "\n",
    "        crit = crit_frac* mean\n",
    "        minlist.append(np.min(temp_list))\n",
    "        min_means.append(mean)\n",
    "        min_crit.append(crit)\n",
    "    \n",
    "    return min_list, min_means, min_crit\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "def get_pruning_mask2(nc, min_crit, min_list,model, conv_dict):\n",
    "    \n",
    "    Mask = [[]]*nc\n",
    "    filters_pruned = [[]]*nc\n",
    "    filters_remain = [[]]*nc\n",
    "    \n",
    "    for k in range(nc):\n",
    "\n",
    "\n",
    "                #Conv output\n",
    "        Scores= min_list[k] \n",
    "        Scores = Scores / np.max(Scores)\n",
    "        len_sc = int(len(Scores))\n",
    "\n",
    "\n",
    "        Criterion = min_crit[k]\n",
    "        mask = np.ones(len_sc)\n",
    "        for i in range(len(Scores)):\n",
    "            temp = Scores[i]-Criterion\n",
    "            if temp <= 0:\n",
    "                mask[i]= 0\n",
    "\n",
    "                \n",
    "        num_rem = int(np.sum(mask))\n",
    "        num_prn = int(len(mask) - num_rem)  \n",
    "        \n",
    "        filters_pruned[k] = num_prn\n",
    "        filters_remain[k] = num_rem\n",
    "\n",
    "        \n",
    "        Test_ten = model.features[conv_dict[k]].weight\n",
    "        \n",
    "        Test_ten = Test_ten.to(device = 'cpu')\n",
    "\n",
    "        Test_ten = Test_ten.detach().numpy()\n",
    "\n",
    "        r,c,ch,f = np.shape(Test_ten)\n",
    "        Test_Mask = [[]]*r\n",
    "        One_ten = np.ones((c,ch,f))\n",
    "        for i in range(r):\n",
    "            Test_Mask[i] = One_ten*mask[i]\n",
    "        X = torch.tensor(Test_Mask).to(device)\n",
    "       \n",
    "        \n",
    "       \n",
    "        \n",
    "        Mask[k] = X\n",
    "    return Mask, filters_pruned, filters_remain\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "\n",
    "def prune_with_mask(nc, model, X, conv_dict):\n",
    "    \n",
    "    for k in range(nc):\n",
    "        mm = prune.custom_from_mask(model.features[conv_dict[k]], name='weight', mask=X)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#################################################################################################################\n",
    "def get_pruned_acc(nc, min_crit, min_list,model, conv_dict,test_loader,device):\n",
    "    \n",
    "    filters_pruned = [[]]*nc\n",
    "    filters_remain = [[]]*nc\n",
    "           \n",
    "    for k in range(nc):\n",
    "        #print(idx)\n",
    "        \n",
    "        \n",
    "        #Conv output\n",
    "        Scores = min_list[k] \n",
    "        Scores = Scores / np.max(Scores)\n",
    "        len_sc = int(len(Scores))\n",
    "\n",
    "\n",
    "        Criterion = min_crit[k]\n",
    "        mask = np.ones(len_sc)\n",
    "        for i in range(len(Scores)):\n",
    "            temp = Scores[i]-Criterion\n",
    "            if temp <= 0:\n",
    "                mask[i]= 0\n",
    "\n",
    "                \n",
    "        num_rem = int(np.sum(mask))\n",
    "        num_prn = int(len(mask) - num_rem)  \n",
    "        \n",
    "        filters_pruned[k] = num_prn\n",
    "        filters_remain[k] = num_rem\n",
    "\n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        Test_ten = model.features[conv_dict[k]].weight\n",
    "        \n",
    "        Test_ten = Test_ten.to(device = 'cpu')\n",
    "\n",
    "        Test_ten = Test_ten.detach().numpy()\n",
    "\n",
    "        r,c,ch,f = np.shape(Test_ten)\n",
    "        Test_Mask = [[]]*r\n",
    "        One_ten = np.ones((c,ch,f))\n",
    "        for i in range(r):\n",
    "            Test_Mask[i] = One_ten*mask[i]\n",
    "        X = torch.tensor(Test_Mask).to(device)\n",
    "       \n",
    "        m1 = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=X)\n",
    "        \n",
    "        \n",
    "        #print(model_accs1[k, idx])\n",
    "        #print(k, crit_frac, num_pruned, pf, T1)\n",
    "    \n",
    "    #device = torch.device('cuda')\n",
    "    \n",
    "    T1 = test(model, test_loader,device)\n",
    "    T1 = 100*T1\n",
    "    \n",
    "    return model, T1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b14df91f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T18:05:31.256063Z",
     "iopub.status.busy": "2023-07-09T18:05:31.255750Z",
     "iopub.status.idle": "2023-07-10T03:09:46.780626Z",
     "shell.execute_reply": "2023-07-10T03:09:46.779475Z"
    },
    "papermill": {
     "duration": 32655.539733,
     "end_time": "2023-07-10T03:09:46.783022",
     "exception": false,
     "start_time": "2023-07-09T18:05:31.243289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n",
      "/tmp/ipykernel_23/4180631273.py:267: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  X = torch.tensor(Test_Mask).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0 93.67999999999999 12.334280303030303 87.6657196969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1 93.54 15.459280303030305 84.54071969696969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 2 93.46 17.09280303030303 82.90719696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475 3 93.47999999999999 16.974431818181817 83.02556818181819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44999999999999996 4 93.56 16.666666666666664 83.33333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44999999999999996 5 93.5 18.039772727272727 81.96022727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42499999999999993 6 93.56 17.779356060606062 82.22064393939394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42499999999999993 7 93.5 18.300189393939394 81.69981060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999 8 93.52000000000001 18.442234848484848 81.55776515151516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999 9 93.52000000000001 18.821022727272727 81.17897727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999 10 93.56 19.223484848484848 80.77651515151516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999 11 93.52000000000001 19.554924242424242 80.44507575757575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999 12 93.56 19.839015151515152 80.16098484848484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999 13 93.46 20.052083333333336 79.94791666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 14 93.56 20.075757575757574 79.92424242424242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 15 93.58 20.241477272727273 79.75852272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 16 93.52000000000001 20.383522727272727 79.61647727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 17 93.56 20.454545454545457 79.54545454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 18 93.56 20.478219696969695 79.52178030303031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 19 93.52000000000001 20.643939393939394 79.35606060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 20 93.52000000000001 20.667613636363637 79.33238636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3749999999999999 21 93.5 20.785984848484848 79.21401515151516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34999999999999987 22 93.47999999999999 20.738636363636363 79.26136363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32499999999999984 23 93.52000000000001 20.80965909090909 79.1903409090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32499999999999984 24 93.5 20.857007575757574 79.14299242424242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999999998 25 93.52000000000001 20.880681818181817 79.11931818181819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999999998 26 93.52000000000001 20.880681818181817 79.11931818181819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999999998 27 93.52000000000001 20.880681818181817 79.11931818181819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999999998 28 93.54 20.928030303030305 79.07196969696969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2999999999999998 29 93.44 20.97537878787879 79.02462121212122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2749999999999998 30 93.54 20.928030303030305 79.07196969696969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2749999999999998 31 93.52000000000001 20.97537878787879 79.02462121212122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2749999999999998 32 93.14 21.046401515151516 78.95359848484848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 33 93.52000000000001 20.97537878787879 79.02462121212122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 34 93.52000000000001 20.97537878787879 79.02462121212122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 35 93.52000000000001 20.97537878787879 79.02462121212122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 36 93.52000000000001 20.99905303030303 79.00094696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 37 93.52000000000001 21.022727272727273 78.97727272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 38 93.52000000000001 21.022727272727273 78.97727272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 39 93.54 21.046401515151516 78.95359848484848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2499999999999998 40 93.16 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 41 93.54 21.046401515151516 78.95359848484848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 42 93.54 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 43 93.54 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 44 93.54 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 45 93.54 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 46 93.54 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 47 93.54 21.070075757575758 78.92992424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 48 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249999999999998 49 93.17999999999999 21.117424242424242 78.88257575757575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 50 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 51 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 52 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 53 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 54 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 55 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 56 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 57 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 58 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 59 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 60 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 61 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 62 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 63 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 64 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 65 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 66 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 67 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 68 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 69 93.54 21.09375 78.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 70 93.56 21.141098484848484 78.85890151515152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 71 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 72 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 73 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 74 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 75 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 76 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 77 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 78 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 79 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 80 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 81 93.56 21.164772727272727 78.83522727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 82 93.56 21.18844696969697 78.81155303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 83 93.56 21.18844696969697 78.81155303030303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 84 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 85 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 86 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 87 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 88 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 89 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 90 93.60000000000001 21.235795454545457 78.76420454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 91 93.56 21.259469696969695 78.74053030303031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 92 93.56 21.259469696969695 78.74053030303031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 93 93.56 21.259469696969695 78.74053030303031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 94 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 95 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 96 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 97 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 98 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 99 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 100 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 101 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 102 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 103 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 104 93.56 21.283143939393938 78.71685606060606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 105 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 106 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 107 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 108 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 109 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 110 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 111 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 112 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 113 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 114 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 115 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 116 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 117 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 118 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 119 93.56 21.306818181818183 78.69318181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 120 93.56 21.330492424242426 78.66950757575758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 121 93.54 21.354166666666664 78.64583333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 122 93.54 21.37784090909091 78.6221590909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 123 93.54 21.37784090909091 78.6221590909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 124 93.54 21.37784090909091 78.6221590909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 125 93.54 21.37784090909091 78.6221590909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 126 93.54 21.37784090909091 78.6221590909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 127 93.54 21.37784090909091 78.6221590909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 128 93.54 21.401515151515152 78.59848484848484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 129 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 130 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 131 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 132 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 133 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 134 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999982 135 93.5 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 136 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 137 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 138 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 139 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 140 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 141 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 142 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17499999999999982 143 93.46 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 144 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 145 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 146 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 147 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 148 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 149 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 150 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 151 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 152 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 153 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 154 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 155 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 156 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 157 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 158 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 159 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 160 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 161 93.52000000000001 21.425189393939394 78.57481060606061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 162 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 163 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 164 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 165 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 166 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 167 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 168 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 169 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 170 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 171 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 172 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 173 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 174 93.54 21.448863636363637 78.55113636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 175 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 176 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 177 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 178 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 179 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 180 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 181 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 182 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 183 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 184 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 185 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 186 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 187 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 188 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 189 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 190 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 191 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 192 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 193 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 194 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 195 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 196 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 197 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 198 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 199 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 200 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 201 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 202 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 203 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 204 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 205 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 206 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 207 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 208 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 209 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 210 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 211 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 212 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 213 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 214 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 215 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 216 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 217 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 218 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 219 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 220 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14999999999999983 221 93.02 21.49621212121212 78.50378787878788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 222 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 223 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 224 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 225 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 226 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 227 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 228 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 229 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 230 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 231 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 232 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 233 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 234 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 235 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 236 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 237 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 238 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 239 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 240 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 241 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 242 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 243 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 244 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 245 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 246 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 247 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999983 248 93.02 21.49621212121212 78.50378787878788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 249 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 250 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 251 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 252 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 253 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 254 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 255 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 256 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 257 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 258 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 259 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 260 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 261 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 262 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 263 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 264 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 265 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 266 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 267 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 268 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 269 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 270 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 271 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 272 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 273 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 274 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 275 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 276 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 277 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 278 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 279 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 280 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 281 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 282 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 283 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 284 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 285 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 286 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 287 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 288 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 289 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 290 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 291 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 292 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 293 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 294 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 295 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 296 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 297 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 298 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 299 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 300 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 301 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 302 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 303 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 304 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 305 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 306 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 307 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 308 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 309 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 310 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 311 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 312 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 313 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 314 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 315 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 316 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 317 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 318 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 319 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 320 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 321 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 322 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 323 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 324 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 325 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 326 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 327 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 328 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 329 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 330 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 331 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 332 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 333 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 334 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 335 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 336 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 337 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 338 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 339 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 340 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 341 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 342 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 343 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 344 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 345 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 346 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 347 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 348 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 349 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 350 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 351 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 352 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 353 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 354 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 355 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 356 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 357 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 358 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 359 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 360 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 361 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 362 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 363 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 364 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 365 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 366 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 367 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 368 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 369 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 370 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 371 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 372 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 373 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 374 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 375 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 376 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 377 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 378 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 379 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 380 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 381 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 382 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 383 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 384 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 385 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 386 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 387 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 388 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 389 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 390 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 391 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 392 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 393 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 394 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 395 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 396 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 397 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 398 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09999999999999984 399 93.52000000000001 21.47253787878788 78.52746212121212\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import HTTPError\n",
    "\n",
    "U = 60\n",
    "\n",
    "# accs = np.zeros(U)\n",
    "\n",
    "accs = []\n",
    "\n",
    "# num_pruned = np.zeros(U)\n",
    "# num_remain = np.zeros(U)\n",
    "\n",
    "num_pruned = []\n",
    "num_remain = []\n",
    "\n",
    "\n",
    "conv_dict = [0,3,7,10,14,17,20,24,27,30, 34, 37, 40]\n",
    "#conv_dict = [0,4,8,11,15,18,22,25]\n",
    "# conv_dict = [0,3,7,10,14,17,20,23,27,30,33,36,40,43,46,49]\n",
    "\n",
    "nc = int(len(conv_dict))\n",
    "num_classes = 10\n",
    "num_samples = 1024\n",
    "\n",
    "fracs = [.99,.9,.8, .7, .65,.6,.5,.4,.3,.2,.1,0]\n",
    "Crit_frac = .5\n",
    "\n",
    "threshold = 93.50\n",
    "frac_count = 0\n",
    "accuracy = 100000\n",
    "uu=0\n",
    "\n",
    "stop_at = 1000\n",
    "freq = {}\n",
    "cnt = 0\n",
    "\n",
    "while Crit_frac > 0:\n",
    "    #print(uu)\n",
    "    mat_features_list_conv, mat_features_list_bn, count = get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter) \n",
    "    diff_list_conv = get_features_diff(nc, num_classes, mat_features_list_conv, conv_dict)\n",
    "    diff_list_bn = get_features_diff(nc, num_classes, mat_features_list_bn, conv_dict)\n",
    "    min_list_conv = get_min_list(nc, num_classes, diff_list_conv)\n",
    "    min_list_bn = get_min_list(nc, num_classes, diff_list_bn)\n",
    "   \n",
    "    minlist_bn, minmeans_bn, min_crit_bn = get_crit_vals(nc, min_list_bn, Crit_frac)\n",
    "    \n",
    "    flag = True\n",
    "    test_model1 = \"\"\n",
    "    while(flag):\n",
    "        try:\n",
    "            test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n",
    "            flag = False\n",
    "            #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n",
    "            #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg11_bn\", pretrained=True)\n",
    "        except HTTPError:\n",
    "            print(\"Error while downloading pretrained model... retrying...\")\n",
    "            flag = True\n",
    "\n",
    "\n",
    "    test_model1 = test_model1.to(device)\n",
    "    \n",
    "    Mask_bn, filters_pruned_bn, filters_remain_bn = get_pruning_mask2(nc, min_crit_bn, min_list_bn,test_model1, conv_dict)\n",
    "    \n",
    "#     num_pruned[uu] = np.sum(filters_pruned_bn)\n",
    "#     num_remain[uu] = np.sum(filters_remain_bn)\n",
    "    fpbn = np.sum(filters_pruned_bn)\n",
    "    frbn = np.sum(filters_remain_bn)\n",
    "    np.append(num_pruned, fpbn)\n",
    "    np.append(num_remain, frbn)\n",
    "    \n",
    "    pf = 100 * (fpbn / (fpbn + frbn))\n",
    "    \n",
    "    for k in range(nc):\n",
    "        mm = prune.custom_from_mask( test_model1.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n",
    "        mm = prune.remove(mm, name='weight')\n",
    "    \n",
    "    T2 = test(test_model1, test_loader, device)\n",
    "    accuracy = T2 * 100\n",
    "    #accs[uu] = T2 *100\n",
    "    np.append(accs,accuracy)\n",
    "    \n",
    "    if accuracy > threshold:\n",
    "        for k in range(nc):\n",
    "            mmm = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n",
    "            mmm = prune.remove(mmm, name='weight')\n",
    "            \n",
    "        \n",
    "        print(Crit_frac, uu, T2*100, pf, 100-pf)\n",
    "    else:\n",
    "        print(Crit_frac, uu, T2*100, pf, 100-pf)\n",
    "        frac_count +=1\n",
    "        Crit_frac = np.maximum(0, Crit_frac - 0.025)\n",
    "        \n",
    "    uu +=1\n",
    "    \n",
    "    if Crit_frac in freq:\n",
    "        freq[Crit_frac] += 1\n",
    "        if freq[Crit_frac] == stop_at:\n",
    "            break\n",
    "    else:\n",
    "        freq[Crit_frac] = 0\n",
    "    \n",
    "    cnt+=1\n",
    "    if(cnt == 400):\n",
    "        break\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d9b12c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T03:09:46.922213Z",
     "iopub.status.busy": "2023-07-10T03:09:46.921128Z",
     "iopub.status.idle": "2023-07-10T03:09:47.028054Z",
     "shell.execute_reply": "2023-07-10T03:09:47.027078Z"
    },
    "papermill": {
     "duration": 0.179617,
     "end_time": "2023-07-10T03:09:47.030552",
     "exception": false,
     "start_time": "2023-07-10T03:09:46.850935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"./pruned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161ef7c",
   "metadata": {
    "papermill": {
     "duration": 0.065892,
     "end_time": "2023-07-10T03:09:47.163847",
     "exception": false,
     "start_time": "2023-07-10T03:09:47.097955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Testing the pruned model (with only zeroed out weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf3abc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T03:09:47.300643Z",
     "iopub.status.busy": "2023-07-10T03:09:47.300239Z",
     "iopub.status.idle": "2023-07-10T03:09:50.455603Z",
     "shell.execute_reply": "2023-07-10T03:09:50.454479Z"
    },
    "papermill": {
     "duration": 3.226316,
     "end_time": "2023-07-10T03:09:50.458030",
     "exception": false,
     "start_time": "2023-07-10T03:09:47.231714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 79.86\n",
      "Total inference time for test data: 672.7657089233398\n",
      "Mean inference time per test batch: 224.25523630777994\n",
      "Standard deviation of inference times per test batch: 71.62840319179816\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab119cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T03:09:50.599660Z",
     "iopub.status.busy": "2023-07-10T03:09:50.598637Z",
     "iopub.status.idle": "2023-07-10T03:09:50.606007Z",
     "shell.execute_reply": "2023-07-10T03:09:50.605127Z"
    },
    "papermill": {
     "duration": 0.07871,
     "end_time": "2023-07-10T03:09:50.608079",
     "exception": false,
     "start_time": "2023-07-10T03:09:50.529369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a_file = open(\"test_vgg16_cifar10.txt\", \"a\")\n",
    "\n",
    "\n",
    "np.savetxt(a_file, [filters_pruned_bn], fmt = '%1.1i')\n",
    "\n",
    "np.savetxt(a_file, [filters_remain_bn], fmt = '%1.1i')\n",
    "\n",
    "np.savetxt(a_file, [accuracy], fmt = '%1.4f')\n",
    "\n",
    "\n",
    "a_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f2e12",
   "metadata": {
    "papermill": {
     "duration": 0.067379,
     "end_time": "2023-07-10T03:09:50.744654",
     "exception": false,
     "start_time": "2023-07-10T03:09:50.677275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Performing architecture modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3eb23c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T03:09:50.884530Z",
     "iopub.status.busy": "2023-07-10T03:09:50.883456Z",
     "iopub.status.idle": "2023-07-10T03:10:04.499264Z",
     "shell.execute_reply": "2023-07-10T03:10:04.498132Z"
    },
    "papermill": {
     "duration": 13.688619,
     "end_time": "2023-07-10T03:10:04.501825",
     "exception": false,
     "start_time": "2023-07-10T03:09:50.813206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-pruning\r\n",
      "  Downloading torch_pruning-1.1.9-py3-none-any.whl (39 kB)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torch-pruning) (2.0.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch-pruning) (1.23.5)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torch-pruning) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torch-pruning) (2.1.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torch-pruning) (1.3.0)\r\n",
      "Installing collected packages: torch-pruning\r\n",
      "Successfully installed torch-pruning-1.1.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch-pruning\n",
    "import torch_pruning as tp\n",
    "    \n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d): #Iterating over all the conv2d layers of the model\n",
    "        channel_indices = [] #Stores indices of the channels to prune within this conv layer\n",
    "        t = module.weight.clone().detach()\n",
    "        t = t.reshape(t.shape[0], -1)\n",
    "        z = torch.all(t == 0, dim=1)\n",
    "        z = z.tolist()\n",
    "        \n",
    "        for i, flag in enumerate(z):\n",
    "            if(flag):\n",
    "                channel_indices.append(i)\n",
    "\n",
    "        if(channel_indices == []):\n",
    "            continue\n",
    "        \n",
    "        # 1. build dependency graph for vgg\n",
    "        DG = tp.DependencyGraph().build_dependency(model, example_inputs=torch.randn(1,3,32,32).to(device))\n",
    "\n",
    "        # 2. Specify the to-be-pruned channels. Here we prune those channels indexed by idxs.\n",
    "        group = DG.get_pruning_group(module, tp.prune_conv_out_channels, idxs=channel_indices)\n",
    "        #print(group)\n",
    "\n",
    "        # 3. prune all grouped layers that are coupled with the conv layer (included).\n",
    "        if DG.check_pruning_group(group): # avoid full pruning, i.e., channels=0.\n",
    "            group.prune()\n",
    "    \n",
    "# 4. Save & Load\n",
    "model.zero_grad() # We don't want to store gradient information\n",
    "torch.save(model, './arch_pruned_model.pth') # without .state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727ed9b",
   "metadata": {
    "papermill": {
     "duration": 0.067447,
     "end_time": "2023-07-10T03:10:04.637652",
     "exception": false,
     "start_time": "2023-07-10T03:10:04.570205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Testing the pruned model (after architecture modifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77de787f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T03:10:04.798321Z",
     "iopub.status.busy": "2023-07-10T03:10:04.797908Z",
     "iopub.status.idle": "2023-07-10T03:10:07.931860Z",
     "shell.execute_reply": "2023-07-10T03:10:07.929920Z"
    },
    "papermill": {
     "duration": 3.206243,
     "end_time": "2023-07-10T03:10:07.934061",
     "exception": false,
     "start_time": "2023-07-10T03:10:04.727818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 79.76\n",
      "Total inference time for test data: 666.2824249267578\n",
      "Mean inference time per test batch: 222.0941416422526\n",
      "Standard deviation of inference times per test batch: 67.8794207128274\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32718.292344,
   "end_time": "2023-07-10T03:10:10.890061",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-09T18:04:52.597717",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
