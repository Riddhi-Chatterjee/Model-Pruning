{"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:20.634198Z","iopub.execute_input":"2023-06-12T19:41:20.634608Z","iopub.status.idle":"2023-06-12T19:41:20.639291Z","shell.execute_reply.started":"2023-06-12T19:41:20.634557Z","shell.execute_reply":"2023-06-12T19:41:20.638169Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n\nimport torch\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn as nn\n\nimport scipy as sp\nfrom scipy.linalg import svdvals\n\nimport numpy as np\n#import powerlaw\n\nimport sklearn\nfrom sklearn.decomposition import TruncatedSVD\n\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch import nn, Tensor\n\nfrom torch.nn.utils import prune as prune\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n#import kneed as kneed\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:20.641278Z","iopub.execute_input":"2023-06-12T19:41:20.642332Z","iopub.status.idle":"2023-06-12T19:41:20.656077Z","shell.execute_reply.started":"2023-06-12T19:41:20.642298Z","shell.execute_reply":"2023-06-12T19:41:20.654731Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n\ndevice = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda\"\n\n\n\nmodel = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg11_bn\", pretrained=True)\n\n\n\n\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:20.657611Z","iopub.execute_input":"2023-06-12T19:41:20.658188Z","iopub.status.idle":"2023-06-12T19:41:21.758816Z","shell.execute_reply.started":"2023-06-12T19:41:20.658156Z","shell.execute_reply":"2023-06-12T19:41:21.757787Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/vgg/cifar100_vgg11_bn-57d0759e.pt\" to /root/.cache/torch/hub/checkpoints/cifar100_vgg11_bn-57d0759e.pt\n100%|██████████| 37.4M/37.4M [00:00<00:00, 91.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nprint(model.features)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:21.760374Z","iopub.execute_input":"2023-06-12T19:41:21.761082Z","iopub.status.idle":"2023-06-12T19:41:21.767437Z","shell.execute_reply.started":"2023-06-12T19:41:21.761025Z","shell.execute_reply":"2023-06-12T19:41:21.766440Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU(inplace=True)\n  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU(inplace=True)\n  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (13): ReLU(inplace=True)\n  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (17): ReLU(inplace=True)\n  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (20): ReLU(inplace=True)\n  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (24): ReLU(inplace=True)\n  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (27): ReLU(inplace=True)\n  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n\n#######################\n\n\n\ntrain_set = torchvision.datasets.CIFAR10('./datasets', train=True, \n                                         download=True, transform=transform)\ntest_set = torchvision.datasets.CIFAR10('./datasets', train=False, \n                                        download=True, transform=transform)\n# Number of subprocesses to use for data loading\nnum_workers = 1\n# How many samples per batch to load\nbatch_size = 1\n# Percentage of training set to use as validation\nvalid_size = 0.5\n\nnum_test = len(test_set)\nindices = list(range(num_test))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_test))\ntest_idx, valid_idx = indices[split:], indices[:split]\n\n# Define samplers for obtaining training and validation batches\ntest_sampler = SubsetRandomSampler(test_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n\n# Prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n                                           num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(test_set, batch_size= 1, sampler=valid_sampler, \n                                           num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=2048, sampler=test_sampler, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:21.770443Z","iopub.execute_input":"2023-06-12T19:41:21.771194Z","iopub.status.idle":"2023-06-12T19:41:23.372298Z","shell.execute_reply.started":"2023-06-12T19:41:21.771159Z","shell.execute_reply":"2023-06-12T19:41:23.371237Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(valid_loader)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:23.373836Z","iopub.execute_input":"2023-06-12T19:41:23.374495Z","iopub.status.idle":"2023-06-12T19:41:23.437294Z","shell.execute_reply.started":"2023-06-12T19:41:23.374450Z","shell.execute_reply":"2023-06-12T19:41:23.435291Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n\ndef ten2mat(tensor):\n    r,c,ch,f = tensor.shape\n    new_dim = [c,r*ch*f]\n    return np.reshape(tensor, new_dim)\n\ndef eff_rank(matrix):\n    frob = np.linalg.norm(matrix, 'fro')\n    svals = svdvals(matrix)\n    S = max(svals)\n    r = frob/S\n    return (r)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:23.440118Z","iopub.execute_input":"2023-06-12T19:41:23.440891Z","iopub.status.idle":"2023-06-12T19:41:23.450454Z","shell.execute_reply.started":"2023-06-12T19:41:23.440847Z","shell.execute_reply":"2023-06-12T19:41:23.448460Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n\n#utility functions\n\n\n#reshape weight/feature tensor into a matrix\ndef ten2mat(tensor):\n    r,c,ch,f = tensor.shape\n    new_dim = [c,r*ch*f]\n    return np.reshape(tensor, new_dim)\n################################################################################################################\n#Compute stable rank\ndef eff_rank(matrix):\n    frob = np.linalg.norm(matrix, 'fro')\n    svals = svdvals(matrix)\n    S = max(svals)\n    r = frob/S\n    return (r)\n\n################################################################################################################\n\n# a dict to store the activations\nactivation = {}\ndef getActivation(name):\n  # the hook signature\n    def hook(model, input, output):\n        activation[name] = output.detach()\n    return hook\n\n################################################################################################################\n\n#Function to get conv+bn feature means\ndef get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter):\n    \n    activation = {}\n    def getActivation(name):\n      # the hook signature\n        def hook(model, input, output):\n            activation[name] = output.detach()\n        return hook\n    \n    mat_features_list_conv = [ [] ]*(nc*num_classes)\n    mat_features_list_bn = [ [] ]*(nc*num_classes)\n\n    count = np.zeros((nc*num_classes))\n\n    #with torch.no_grad():\n    for i in range(num_samples):\n        \n        try:\n            image,label = next(dataiter)\n        except StopIteration:\n            dataiter = iter(train_loader)\n            image,label = next(dataiter)\n        \n        \n        l2 =label.detach().numpy()\n        l2 = l2[0]\n        #print(l2)\n        for j in range(nc):#range(len(conv_dict)):\n            activation = {}\n            z1 = conv_dict[j]\n            z2 = z1 + 1\n\n            #print(z1,z2)\n            h1 = model.features[z1].register_forward_hook(getActivation('conv2d'))\n            h2 = model.features[z2].register_forward_hook(getActivation('bn'))\n\n            output = model(image.to(device))\n\n            Xx1 = activation['conv2d']\n            Xx2 = activation['bn']\n\n            Xx1 = Xx1.to(device = 'cpu')\n            Xx2 = Xx2.to(device = 'cpu')\n\n            Xx01 = Xx1.detach().numpy()\n            Xx02 = Xx2.detach().numpy()\n\n            temp_mat1 = ten2mat(Xx01)\n            temp_mat2 = ten2mat(Xx02)\n\n            temp_idx = int(num_classes*j + l2)\n\n            count[temp_idx]+=1\n            #print(i, np.linalg.norm(temp_mat1),np.linalg.norm(temp_mat2), np.linalg.norm(temp_mat3), l2, j, z1, temp_idx)\n\n            l31 = len(mat_features_list_conv[temp_idx])\n            l32 = len(mat_features_list_bn[temp_idx])\n\n            if l31 == 0:\n                mat_features_list_conv[temp_idx] = temp_mat1\n\n            else:\n                mat_features_list_conv[temp_idx] = mat_features_list_conv[temp_idx] + temp_mat1\n\n            if l32 == 0:\n                mat_features_list_bn[temp_idx] = temp_mat2\n\n            else:\n                mat_features_list_bn[temp_idx] = mat_features_list_bn[temp_idx] + temp_mat2\n\n\n            h1.remove()\n            h2.remove()\n       \n    for i in range(nc*num_classes):\n        mat_features_list_conv[i] = mat_features_list_conv[i] / count[i]\n        mat_features_list_bn[i] = mat_features_list_bn[i] / count[i]\n    \n    return mat_features_list_conv, mat_features_list_bn, count\n\n\n#################################################################################################################\n\n#function to get differences between features\n\ndef get_features_diff(nc, num_classes, mat_features_list, conv_dict):\n    \n    mat_diff_list = []\n    \n    ll = int(0.5 * num_classes * (num_classes - 1))\n\n\n    count_list = [ [[]]*ll ]*nc\n\n    for k in range(nc):\n        idx1 = 0\n        idx2 = num_classes*k\n        temp_list = [[]]*ll\n\n        for i in range(num_classes):\n            for j in range(i+1,num_classes):\n                #print(idx1)\n                ti = i+idx2\n                tj = j+idx2\n                temp1 = mat_features_list[ti] - mat_features_list[tj]\n                \n                temp_list[idx1] = temp1\n\n                count_list[k][idx1]= (i,j)\n                idx1+=1\n        mat_diff_list.append([temp_list])\n\n        \n    return mat_diff_list\n\n#################################################################################################################\n        \ndef get_min_list(nc, num_classes, mat_diff_list):\n    min_list = []\n    ll = int(0.5 * num_classes * (num_classes - 1))\n\n    for k in range(nc):\n        layer_list = mat_diff_list[k][0]\n\n\n        tempmat = layer_list[0]\n        \n        Y_conv = np.shape(tempmat)\n        num_channels = Y_conv[0]\n        #print(ll)\n        temp_min_list= [[]]*num_channels\n\n\n        for i in range(ll):\n            temp1  = layer_list[i]\n\n\n\n            temp1n = np.linalg.norm(temp1, axis=1)\n\n\n            for j in range(num_channels):           \n                if bool(temp_min_list[j]):\n                    if temp_min_list[j] > temp1n[j]:\n                        temp_min_list[j] = temp1n[j]                    \n                else:\n                    temp_min_list[j] = temp1n[j]\n\n\n\n\n        min_list.append(temp_min_list)\n    return min_list\n\n\n################################################################################################################\n\ndef test(model, data_loader, device):\n    acc = 0  # TODO compute top1\n    correct_samples = 0\n    total_samples = 0\n    model.eval()\n    with torch.no_grad():\n        for (idx, (x, t)) in enumerate(data_loader):\n            x = model.forward(x.to(device))\n            t = t.to(device)\n            _, indices = torch.max(x, 1)\n            correct_samples += torch.sum(indices == t)\n            total_samples += t.shape[0]\n\n    acc = float(correct_samples) / total_samples\n    return acc\n\n################################################################################################################\n\ndef get_crit_vals(nc, min_list, crit_frac):\n    minlist = []\n    min_means = []\n    min_crit = []\n    for i in range(nc):\n        temp_list = min_list[i] / np.max(min_list[i])\n        mean = np.mean(temp_list)\n\n\n        #print(i,mean_conv, mean_bn)\n\n        crit = crit_frac* mean\n        minlist.append(np.min(temp_list))\n        min_means.append(mean)\n        min_crit.append(crit)\n    \n    return min_list, min_means, min_crit\n\n################################################################################################################\n\ndef get_pruning_mask2(nc, min_crit, min_list,model, conv_dict):\n    \n    Mask = [[]]*nc\n    filters_pruned = [[]]*nc\n    filters_remain = [[]]*nc\n    \n    for k in range(nc):\n\n\n                #Conv output\n        Scores= min_list[k] \n        Scores = Scores / np.max(Scores)\n        len_sc = int(len(Scores))\n\n\n        Criterion = min_crit[k]\n        mask = np.ones(len_sc)\n        for i in range(len(Scores)):\n            temp = Scores[i]-Criterion\n            if temp <= 0:\n                mask[i]= 0\n\n                \n        num_rem = int(np.sum(mask))\n        num_prn = int(len(mask) - num_rem)  \n        \n        filters_pruned[k] = num_prn\n        filters_remain[k] = num_rem\n\n        \n        Test_ten = model.features[conv_dict[k]].weight\n        \n        Test_ten = Test_ten.to(device = 'cpu')\n\n        Test_ten = Test_ten.detach().numpy()\n\n        r,c,ch,f = np.shape(Test_ten)\n        Test_Mask = [[]]*r\n        One_ten = np.ones((c,ch,f))\n        for i in range(r):\n            Test_Mask[i] = One_ten*mask[i]\n        X = torch.tensor(Test_Mask).to(device)\n       \n        \n       \n        \n        Mask[k] = X\n    return Mask, filters_pruned, filters_remain\n\n\n#################################################################################################################\n\ndef prune_with_mask(nc, model, X, conv_dict):\n    \n    for k in range(nc):\n        mm = prune.custom_from_mask(model.features[conv_dict[k]], name='weight', mask=X)\n    \n    return model\n\n#################################################################################################################\ndef get_pruned_acc(nc, min_crit, min_list,model, conv_dict,test_loader,device):\n    \n    filters_pruned = [[]]*nc\n    filters_remain = [[]]*nc\n           \n    for k in range(nc):\n        #print(idx)\n        \n        \n        #Conv output\n        Scores = min_list[k] \n        Scores = Scores / np.max(Scores)\n        len_sc = int(len(Scores))\n\n\n        Criterion = min_crit[k]\n        mask = np.ones(len_sc)\n        for i in range(len(Scores)):\n            temp = Scores[i]-Criterion\n            if temp <= 0:\n                mask[i]= 0\n\n                \n        num_rem = int(np.sum(mask))\n        num_prn = int(len(mask) - num_rem)  \n        \n        filters_pruned[k] = num_prn\n        filters_remain[k] = num_rem\n\n      \n        \n        \n        \n        Test_ten = model.features[conv_dict[k]].weight\n        \n        Test_ten = Test_ten.to(device = 'cpu')\n\n        Test_ten = Test_ten.detach().numpy()\n\n        r,c,ch,f = np.shape(Test_ten)\n        Test_Mask = [[]]*r\n        One_ten = np.ones((c,ch,f))\n        for i in range(r):\n            Test_Mask[i] = One_ten*mask[i]\n        X = torch.tensor(Test_Mask).to(device)\n       \n        m1 = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=X)\n        \n        \n        #print(model_accs1[k, idx])\n        #print(k, crit_frac, num_pruned, pf, T1)\n    \n    #device = torch.device('cuda')\n    \n    T1 = test(model, test_loader,device)\n    T1 = 100*T1\n    \n    return model, T1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:23.455322Z","iopub.execute_input":"2023-06-12T19:41:23.457421Z","iopub.status.idle":"2023-06-12T19:41:23.507817Z","shell.execute_reply.started":"2023-06-12T19:41:23.457395Z","shell.execute_reply":"2023-06-12T19:41:23.506771Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n\nU = 60\n\n# accs = np.zeros(U)\n\naccs = []\n\n# num_pruned = np.zeros(U)\n# num_remain = np.zeros(U)\n\nnum_pruned = []\nnum_remain = []\n\n\n# conv_dict = [0,3,7,10,14,17,20,24,27,30, 34, 37, 40]\nconv_dict = [0,4,8,11,15,18,22,25]\n# conv_dict = [0,3,7,10,14,17,20,23,27,30,33,36,40,43,46,49]\n\nnc = int(len(conv_dict))\nnum_classes = 10\nnum_samples = 1024\n\nfracs = [.99,.9,.8, .7, .65,.6,.5,.4,.3,.2,.1,0]\nCrit_frac = .5\n\nthreshold = 56.00\nfrac_count = 0\naccuracy = 100000\nuu=0\n\nwhile Crit_frac > 0:\n    #print(uu)\n    mat_features_list_conv, mat_features_list_bn, count = get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter) \n    diff_list_conv = get_features_diff(nc, num_classes, mat_features_list_conv, conv_dict)\n    diff_list_bn = get_features_diff(nc, num_classes, mat_features_list_bn, conv_dict)\n    min_list_conv = get_min_list(nc, num_classes, diff_list_conv)\n    min_list_bn = get_min_list(nc, num_classes, diff_list_bn)\n   \n    minlist_bn, minmeans_bn, min_crit_bn = get_crit_vals(nc, min_list_bn, Crit_frac)\n    \n    #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n    #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n    test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg11_bn\", pretrained=True)\n\n\n    test_model1 = test_model1.to(device)\n    \n    Mask_bn, filters_pruned_bn, filters_remain_bn = get_pruning_mask2(nc, min_crit_bn, min_list_bn,test_model1, conv_dict)\n    \n#     num_pruned[uu] = np.sum(filters_pruned_bn)\n#     num_remain[uu] = np.sum(filters_remain_bn)\n    fpbn = np.sum(filters_pruned_bn)\n    frbn = np.sum(filters_remain_bn)\n    np.append(num_pruned, fpbn)\n    np.append(num_remain, frbn)\n    \n    pf = 100 * (fpbn / (fpbn + frbn))\n    \n    for k in range(nc):\n        mm = prune.custom_from_mask( test_model1.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n        mm = prune.remove(mm, name='weight')\n    \n    T2 = test(test_model1, test_loader, device)\n    accuracy = T2 * 100\n    #accs[uu] = T2 *100\n    np.append(accs,accuracy)\n    \n    if accuracy >= threshold:\n        for k in range(nc):\n            mmm = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n            mmm = prune.remove(mmm, name='weight')\n            \n        \n        print(Crit_frac, uu, T2*100, pf, 100-pf)\n    else:\n        print(Crit_frac, uu, T2*100, pf, 100-pf)\n        frac_count +=1\n        Crit_frac = np.maximum(0, Crit_frac - 0.025)\n        \n    uu +=1\n        \n    \n    \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:41:23.510477Z","iopub.execute_input":"2023-06-12T19:41:23.511881Z","iopub.status.idle":"2023-06-12T19:46:33.606320Z","shell.execute_reply.started":"2023-06-12T19:41:23.511854Z","shell.execute_reply":"2023-06-12T19:46:33.604814Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.5 0 0.16 4.178779069767442 95.82122093023256\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.475 1 0.12 3.77906976744186 96.22093023255815\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.44999999999999996 2 0.12 2.688953488372093 97.31104651162791\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.42499999999999993 3 0.26 2.252906976744186 97.74709302325581\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.3999999999999999 4 0.2 2.1075581395348837 97.89244186046511\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.3749999999999999 5 0.18 1.4171511627906976 98.5828488372093\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.34999999999999987 6 0.16 1.1991279069767442 98.80087209302326\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m     test_model1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchenyaofo/pytorch-cifar-models\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar100_vgg11_bn\u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m     test_model1 \u001b[38;5;241m=\u001b[39m test_model1\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 47\u001b[0m     Mask_bn, filters_pruned_bn, filters_remain_bn \u001b[38;5;241m=\u001b[39m \u001b[43mget_pruning_mask2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_crit_bn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_list_bn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_model1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#     num_pruned[uu] = np.sum(filters_pruned_bn)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#     num_remain[uu] = np.sum(filters_remain_bn)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     fpbn \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(filters_pruned_bn)\n","Cell \u001b[0;32mIn[17], line 267\u001b[0m, in \u001b[0;36mget_pruning_mask2\u001b[0;34m(nc, min_crit, min_list, model, conv_dict)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(r):\n\u001b[1;32m    266\u001b[0m         Test_Mask[i] \u001b[38;5;241m=\u001b[39m One_ten\u001b[38;5;241m*\u001b[39mmask[i]\n\u001b[0;32m--> 267\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTest_Mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    272\u001b[0m     Mask[k] \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Mask, filters_pruned, filters_remain\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"\n\na_file = open(\"test_vgg11_cifar100.txt\", \"a\")\n\n\nnp.savetxt(a_file, [filters_pruned_bn], fmt = '%1.1i')\n\nnp.savetxt(a_file, [filters_remain_bn], fmt = '%1.1i')\n\nnp.savetxt(a_file, [accuracy], fmt = '%1.4f')\n\n\na_file.close()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:46:33.608321Z","iopub.status.idle":"2023-06-12T19:46:33.608850Z","shell.execute_reply.started":"2023-06-12T19:46:33.608597Z","shell.execute_reply":"2023-06-12T19:46:33.608635Z"},"trusted":true},"execution_count":null,"outputs":[]}]}