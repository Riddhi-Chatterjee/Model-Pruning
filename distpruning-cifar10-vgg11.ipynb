{"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:42.948629Z","iopub.execute_input":"2023-06-12T19:28:42.949009Z","iopub.status.idle":"2023-06-12T19:28:42.955039Z","shell.execute_reply.started":"2023-06-12T19:28:42.948979Z","shell.execute_reply":"2023-06-12T19:28:42.953908Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n\nimport torch\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torch.nn as nn\n\nimport scipy as sp\nfrom scipy.linalg import svdvals\n\nimport numpy as np\n#import powerlaw\n\nimport sklearn\nfrom sklearn.decomposition import TruncatedSVD\n\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom torch import nn, Tensor\n\nfrom torch.nn.utils import prune as prune\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n#import kneed as kneed\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:42.957218Z","iopub.execute_input":"2023-06-12T19:28:42.957766Z","iopub.status.idle":"2023-06-12T19:28:47.541972Z","shell.execute_reply.started":"2023-06-12T19:28:42.957734Z","shell.execute_reply":"2023-06-12T19:28:47.540935Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\ndevice = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda\"\n\n\n\nmodel = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n\n\n\n\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:47.544327Z","iopub.execute_input":"2023-06-12T19:28:47.545333Z","iopub.status.idle":"2023-06-12T19:28:52.467504Z","shell.execute_reply.started":"2023-06-12T19:28:47.545297Z","shell.execute_reply":"2023-06-12T19:28:52.466529Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/vgg/cifar10_vgg11_bn-eaeebf42.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_vgg11_bn-eaeebf42.pt\n100%|██████████| 37.3M/37.3M [00:00<00:00, 130MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nprint(model.features)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:52.469080Z","iopub.execute_input":"2023-06-12T19:28:52.469464Z","iopub.status.idle":"2023-06-12T19:28:52.475007Z","shell.execute_reply.started":"2023-06-12T19:28:52.469425Z","shell.execute_reply":"2023-06-12T19:28:52.474117Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU(inplace=True)\n  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU(inplace=True)\n  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (13): ReLU(inplace=True)\n  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (17): ReLU(inplace=True)\n  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (20): ReLU(inplace=True)\n  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (24): ReLU(inplace=True)\n  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (27): ReLU(inplace=True)\n  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n\n#######################\n\n\n\ntrain_set = torchvision.datasets.CIFAR10('./datasets', train=True, \n                                         download=True, transform=transform)\ntest_set = torchvision.datasets.CIFAR10('./datasets', train=False, \n                                        download=True, transform=transform)\n# Number of subprocesses to use for data loading\nnum_workers = 1\n# How many samples per batch to load\nbatch_size = 1\n# Percentage of training set to use as validation\nvalid_size = 0.5\n\nnum_test = len(test_set)\nindices = list(range(num_test))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_test))\ntest_idx, valid_idx = indices[split:], indices[:split]\n\n# Define samplers for obtaining training and validation batches\ntest_sampler = SubsetRandomSampler(test_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n\n# Prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n                                           num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(test_set, batch_size= 1, sampler=valid_sampler, \n                                           num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=2048, sampler=test_sampler, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:52.477845Z","iopub.execute_input":"2023-06-12T19:28:52.478405Z","iopub.status.idle":"2023-06-12T19:28:58.805607Z","shell.execute_reply.started":"2023-06-12T19:28:52.478374Z","shell.execute_reply":"2023-06-12T19:28:58.804593Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:02<00:00, 62286659.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(valid_loader)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:58.806980Z","iopub.execute_input":"2023-06-12T19:28:58.811152Z","iopub.status.idle":"2023-06-12T19:28:58.867796Z","shell.execute_reply.started":"2023-06-12T19:28:58.811108Z","shell.execute_reply":"2023-06-12T19:28:58.865972Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n\ndef ten2mat(tensor):\n    r,c,ch,f = tensor.shape\n    new_dim = [c,r*ch*f]\n    return np.reshape(tensor, new_dim)\n\ndef eff_rank(matrix):\n    frob = np.linalg.norm(matrix, 'fro')\n    svals = svdvals(matrix)\n    S = max(svals)\n    r = frob/S\n    return (r)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:58.870482Z","iopub.execute_input":"2023-06-12T19:28:58.871205Z","iopub.status.idle":"2023-06-12T19:28:58.878911Z","shell.execute_reply.started":"2023-06-12T19:28:58.871161Z","shell.execute_reply":"2023-06-12T19:28:58.878109Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n\n#utility functions\n\n\n#reshape weight/feature tensor into a matrix\ndef ten2mat(tensor):\n    r,c,ch,f = tensor.shape\n    new_dim = [c,r*ch*f]\n    return np.reshape(tensor, new_dim)\n################################################################################################################\n#Compute stable rank\ndef eff_rank(matrix):\n    frob = np.linalg.norm(matrix, 'fro')\n    svals = svdvals(matrix)\n    S = max(svals)\n    r = frob/S\n    return (r)\n\n################################################################################################################\n\n# a dict to store the activations\nactivation = {}\ndef getActivation(name):\n  # the hook signature\n    def hook(model, input, output):\n        activation[name] = output.detach()\n    return hook\n\n################################################################################################################\n\n#Function to get conv+bn feature means\ndef get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter):\n    \n    activation = {}\n    def getActivation(name):\n      # the hook signature\n        def hook(model, input, output):\n            activation[name] = output.detach()\n        return hook\n    \n    mat_features_list_conv = [ [] ]*(nc*num_classes)\n    mat_features_list_bn = [ [] ]*(nc*num_classes)\n\n    count = np.zeros((nc*num_classes))\n\n    #with torch.no_grad():\n    for i in range(num_samples):\n        \n        try:\n            image,label = next(dataiter)\n        except StopIteration:\n            dataiter = iter(train_loader)\n            image,label = next(dataiter)\n        \n        \n        l2 =label.detach().numpy()\n        l2 = l2[0]\n        #print(l2)\n        for j in range(nc):#range(len(conv_dict)):\n            activation = {}\n            z1 = conv_dict[j]\n            z2 = z1 + 1\n\n            #print(z1,z2)\n            h1 = model.features[z1].register_forward_hook(getActivation('conv2d'))\n            h2 = model.features[z2].register_forward_hook(getActivation('bn'))\n\n            output = model(image.to(device))\n\n            Xx1 = activation['conv2d']\n            Xx2 = activation['bn']\n\n            Xx1 = Xx1.to(device = 'cpu')\n            Xx2 = Xx2.to(device = 'cpu')\n\n            Xx01 = Xx1.detach().numpy()\n            Xx02 = Xx2.detach().numpy()\n\n            temp_mat1 = ten2mat(Xx01)\n            temp_mat2 = ten2mat(Xx02)\n\n            temp_idx = int(num_classes*j + l2)\n\n            count[temp_idx]+=1\n            #print(i, np.linalg.norm(temp_mat1),np.linalg.norm(temp_mat2), np.linalg.norm(temp_mat3), l2, j, z1, temp_idx)\n\n            l31 = len(mat_features_list_conv[temp_idx])\n            l32 = len(mat_features_list_bn[temp_idx])\n\n            if l31 == 0:\n                mat_features_list_conv[temp_idx] = temp_mat1\n\n            else:\n                mat_features_list_conv[temp_idx] = mat_features_list_conv[temp_idx] + temp_mat1\n\n            if l32 == 0:\n                mat_features_list_bn[temp_idx] = temp_mat2\n\n            else:\n                mat_features_list_bn[temp_idx] = mat_features_list_bn[temp_idx] + temp_mat2\n\n\n            h1.remove()\n            h2.remove()\n       \n    for i in range(nc*num_classes):\n        mat_features_list_conv[i] = mat_features_list_conv[i] / count[i]\n        mat_features_list_bn[i] = mat_features_list_bn[i] / count[i]\n    \n    return mat_features_list_conv, mat_features_list_bn, count\n\n\n#################################################################################################################\n\n#function to get differences between features\n\ndef get_features_diff(nc, num_classes, mat_features_list, conv_dict):\n    \n    mat_diff_list = []\n    \n    ll = int(0.5 * num_classes * (num_classes - 1))\n\n\n    count_list = [ [[]]*ll ]*nc\n\n    for k in range(nc):\n        idx1 = 0\n        idx2 = num_classes*k\n        temp_list = [[]]*ll\n\n        for i in range(num_classes):\n            for j in range(i+1,num_classes):\n                #print(idx1)\n                ti = i+idx2\n                tj = j+idx2\n                temp1 = mat_features_list[ti] - mat_features_list[tj]\n                \n                temp_list[idx1] = temp1\n\n                count_list[k][idx1]= (i,j)\n                idx1+=1\n        mat_diff_list.append([temp_list])\n\n        \n    return mat_diff_list\n\n#################################################################################################################\n        \ndef get_min_list(nc, num_classes, mat_diff_list):\n    min_list = []\n    ll = int(0.5 * num_classes * (num_classes - 1))\n\n    for k in range(nc):\n        layer_list = mat_diff_list[k][0]\n\n\n        tempmat = layer_list[0]\n        \n        Y_conv = np.shape(tempmat)\n        num_channels = Y_conv[0]\n        #print(ll)\n        temp_min_list= [[]]*num_channels\n\n\n        for i in range(ll):\n            temp1  = layer_list[i]\n\n\n\n            temp1n = np.linalg.norm(temp1, axis=1)\n\n\n            for j in range(num_channels):           \n                if bool(temp_min_list[j]):\n                    if temp_min_list[j] > temp1n[j]:\n                        temp_min_list[j] = temp1n[j]                    \n                else:\n                    temp_min_list[j] = temp1n[j]\n\n\n\n\n        min_list.append(temp_min_list)\n    return min_list\n\n\n################################################################################################################\n\ndef test(model, data_loader, device):\n    acc = 0  # TODO compute top1\n    correct_samples = 0\n    total_samples = 0\n    model.eval()\n    with torch.no_grad():\n        for (idx, (x, t)) in enumerate(data_loader):\n            x = model.forward(x.to(device))\n            t = t.to(device)\n            _, indices = torch.max(x, 1)\n            correct_samples += torch.sum(indices == t)\n            total_samples += t.shape[0]\n\n    acc = float(correct_samples) / total_samples\n    return acc\n\n################################################################################################################\n\ndef get_crit_vals(nc, min_list, crit_frac):\n    minlist = []\n    min_means = []\n    min_crit = []\n    for i in range(nc):\n        temp_list = min_list[i] / np.max(min_list[i])\n        mean = np.mean(temp_list)\n\n\n        #print(i,mean_conv, mean_bn)\n\n        crit = crit_frac* mean\n        minlist.append(np.min(temp_list))\n        min_means.append(mean)\n        min_crit.append(crit)\n    \n    return min_list, min_means, min_crit\n\n################################################################################################################\n\ndef get_pruning_mask2(nc, min_crit, min_list,model, conv_dict):\n    \n    Mask = [[]]*nc\n    filters_pruned = [[]]*nc\n    filters_remain = [[]]*nc\n    \n    for k in range(nc):\n\n\n                #Conv output\n        Scores= min_list[k] \n        Scores = Scores / np.max(Scores)\n        len_sc = int(len(Scores))\n\n\n        Criterion = min_crit[k]\n        mask = np.ones(len_sc)\n        for i in range(len(Scores)):\n            temp = Scores[i]-Criterion\n            if temp <= 0:\n                mask[i]= 0\n\n                \n        num_rem = int(np.sum(mask))\n        num_prn = int(len(mask) - num_rem)  \n        \n        filters_pruned[k] = num_prn\n        filters_remain[k] = num_rem\n\n        \n        Test_ten = model.features[conv_dict[k]].weight\n        \n        Test_ten = Test_ten.to(device = 'cpu')\n\n        Test_ten = Test_ten.detach().numpy()\n\n        r,c,ch,f = np.shape(Test_ten)\n        Test_Mask = [[]]*r\n        One_ten = np.ones((c,ch,f))\n        for i in range(r):\n            Test_Mask[i] = One_ten*mask[i]\n        X = torch.tensor(Test_Mask).to(device)\n       \n        \n       \n        \n        Mask[k] = X\n    return Mask, filters_pruned, filters_remain\n\n\n#################################################################################################################\n\ndef prune_with_mask(nc, model, X, conv_dict):\n    \n    for k in range(nc):\n        mm = prune.custom_from_mask(model.features[conv_dict[k]], name='weight', mask=X)\n    \n    return model\n\n#################################################################################################################\ndef get_pruned_acc(nc, min_crit, min_list,model, conv_dict,test_loader,device):\n    \n    filters_pruned = [[]]*nc\n    filters_remain = [[]]*nc\n           \n    for k in range(nc):\n        #print(idx)\n        \n        \n        #Conv output\n        Scores = min_list[k] \n        Scores = Scores / np.max(Scores)\n        len_sc = int(len(Scores))\n\n\n        Criterion = min_crit[k]\n        mask = np.ones(len_sc)\n        for i in range(len(Scores)):\n            temp = Scores[i]-Criterion\n            if temp <= 0:\n                mask[i]= 0\n\n                \n        num_rem = int(np.sum(mask))\n        num_prn = int(len(mask) - num_rem)  \n        \n        filters_pruned[k] = num_prn\n        filters_remain[k] = num_rem\n\n      \n        \n        \n        \n        Test_ten = model.features[conv_dict[k]].weight\n        \n        Test_ten = Test_ten.to(device = 'cpu')\n\n        Test_ten = Test_ten.detach().numpy()\n\n        r,c,ch,f = np.shape(Test_ten)\n        Test_Mask = [[]]*r\n        One_ten = np.ones((c,ch,f))\n        for i in range(r):\n            Test_Mask[i] = One_ten*mask[i]\n        X = torch.tensor(Test_Mask).to(device)\n       \n        m1 = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=X)\n        \n        \n        #print(model_accs1[k, idx])\n        #print(k, crit_frac, num_pruned, pf, T1)\n    \n    #device = torch.device('cuda')\n    \n    T1 = test(model, test_loader,device)\n    T1 = 100*T1\n    \n    return model, T1\n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:58.880378Z","iopub.execute_input":"2023-06-12T19:28:58.881022Z","iopub.status.idle":"2023-06-12T19:28:59.189374Z","shell.execute_reply.started":"2023-06-12T19:28:58.880985Z","shell.execute_reply":"2023-06-12T19:28:59.188284Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n\nU = 60\n\n# accs = np.zeros(U)\n\naccs = []\n\n# num_pruned = np.zeros(U)\n# num_remain = np.zeros(U)\n\nnum_pruned = []\nnum_remain = []\n\n\n# conv_dict = [0,3,7,10,14,17,20,24,27,30, 34, 37, 40]\nconv_dict = [0,4,8,11,15,18,22,25]\n# conv_dict = [0,3,7,10,14,17,20,23,27,30,33,36,40,43,46,49]\n\nnc = int(len(conv_dict))\nnum_classes = 10\nnum_samples = 1024\n\nfracs = [.99,.9,.8, .7, .65,.6,.5,.4,.3,.2,.1,0]\nCrit_frac = .5\n\nthreshold = 56.00\nfrac_count = 0\naccuracy = 100000\nuu=0\n\nwhile Crit_frac > 0:\n    #print(uu)\n    mat_features_list_conv, mat_features_list_bn, count = get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter) \n    diff_list_conv = get_features_diff(nc, num_classes, mat_features_list_conv, conv_dict)\n    diff_list_bn = get_features_diff(nc, num_classes, mat_features_list_bn, conv_dict)\n    min_list_conv = get_min_list(nc, num_classes, diff_list_conv)\n    min_list_bn = get_min_list(nc, num_classes, diff_list_bn)\n   \n    minlist_bn, minmeans_bn, min_crit_bn = get_crit_vals(nc, min_list_bn, Crit_frac)\n    \n    test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n    #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n    #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg11_bn\", pretrained=True)\n\n\n    test_model1 = test_model1.to(device)\n    \n    Mask_bn, filters_pruned_bn, filters_remain_bn = get_pruning_mask2(nc, min_crit_bn, min_list_bn,test_model1, conv_dict)\n    \n#     num_pruned[uu] = np.sum(filters_pruned_bn)\n#     num_remain[uu] = np.sum(filters_remain_bn)\n    fpbn = np.sum(filters_pruned_bn)\n    frbn = np.sum(filters_remain_bn)\n    np.append(num_pruned, fpbn)\n    np.append(num_remain, frbn)\n    \n    pf = 100 * (fpbn / (fpbn + frbn))\n    \n    for k in range(nc):\n        mm = prune.custom_from_mask( test_model1.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n        mm = prune.remove(mm, name='weight')\n    \n    T2 = test(test_model1, test_loader, device)\n    accuracy = T2 * 100\n    #accs[uu] = T2 *100\n    np.append(accs,accuracy)\n    \n    if accuracy >= threshold:\n        for k in range(nc):\n            mmm = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n            mmm = prune.remove(mmm, name='weight')\n            \n        \n        print(Crit_frac, uu, T2*100, pf, 100-pf)\n    else:\n        print(Crit_frac, uu, T2*100, pf, 100-pf)\n        frac_count +=1\n        Crit_frac = np.maximum(0, Crit_frac - 0.025)\n        \n    uu +=1\n        \n    \n    \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-06-12T19:28:59.191076Z","iopub.execute_input":"2023-06-12T19:28:59.192364Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n/tmp/ipykernel_28/4180631273.py:267: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n  X = torch.tensor(Test_Mask).to(device)\n","output_type":"stream"},{"name":"stdout","text":"0.5 0 71.96000000000001 9.70203488372093 90.29796511627907\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.5 1 71.2 11.954941860465116 88.04505813953489\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.5 2 70.19999999999999 13.98982558139535 86.01017441860465\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.5 3 70.32000000000001 15.29796511627907 84.70203488372093\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"name":"stdout","text":"0.5 4 70.26 16.170058139534884 83.82994186046511\n","output_type":"stream"},{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\na_file = open(\"test_vgg11_cifar100.txt\", \"a\")\n\n\nnp.savetxt(a_file, [filters_pruned_bn], fmt = '%1.1i')\n\nnp.savetxt(a_file, [filters_remain_bn], fmt = '%1.1i')\n\nnp.savetxt(a_file, [accuracy], fmt = '%1.4f')\n\n\na_file.close()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}