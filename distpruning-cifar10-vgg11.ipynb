{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:34:59.251020Z","iopub.status.busy":"2023-06-12T18:34:59.250635Z","iopub.status.idle":"2023-06-12T18:34:59.255367Z","shell.execute_reply":"2023-06-12T18:34:59.254501Z","shell.execute_reply.started":"2023-06-12T18:34:59.250992Z"},"trusted":true},"outputs":[],"source":["#!/usr/bin/env python\n","# coding: utf-8"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:34:59.258271Z","iopub.status.busy":"2023-06-12T18:34:59.257334Z","iopub.status.idle":"2023-06-12T18:34:59.271428Z","shell.execute_reply":"2023-06-12T18:34:59.270373Z","shell.execute_reply.started":"2023-06-12T18:34:59.258239Z"},"trusted":true},"outputs":[],"source":["\n","\n","import torch\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","\n","import scipy as sp\n","from scipy.linalg import svdvals\n","\n","import numpy as np\n","#import powerlaw\n","\n","import sklearn\n","from sklearn.decomposition import TruncatedSVD\n","\n","import matplotlib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torch import nn, Tensor\n","\n","from torch.nn.utils import prune as prune\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","#import kneed as kneed\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:34:59.273427Z","iopub.status.busy":"2023-06-12T18:34:59.272580Z","iopub.status.idle":"2023-06-12T18:35:00.557461Z","shell.execute_reply":"2023-06-12T18:35:00.556511Z","shell.execute_reply.started":"2023-06-12T18:34:59.273393Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /Users/riddhichatterjee/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/vgg/cifar10_vgg11_bn-eaeebf42.pt\" to /Users/riddhichatterjee/.cache/torch/hub/checkpoints/cifar10_vgg11_bn-eaeebf42.pt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a12d47fa8ec54c7eb6334588ca660ac2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/37.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["\n","\n","device = \"cpu\"\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","\n","\n","\n","model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n","\n","\n","\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:35:00.560618Z","iopub.status.busy":"2023-06-12T18:35:00.559878Z","iopub.status.idle":"2023-06-12T18:35:00.566952Z","shell.execute_reply":"2023-06-12T18:35:00.566033Z","shell.execute_reply.started":"2023-06-12T18:35:00.560585Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU(inplace=True)\n","  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (6): ReLU(inplace=True)\n","  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU(inplace=True)\n","  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (13): ReLU(inplace=True)\n","  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (17): ReLU(inplace=True)\n","  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (20): ReLU(inplace=True)\n","  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (24): ReLU(inplace=True)\n","  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (27): ReLU(inplace=True)\n","  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",")\n"]}],"source":["\n","\n","print(model.features)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:35:00.569124Z","iopub.status.busy":"2023-06-12T18:35:00.568233Z","iopub.status.idle":"2023-06-12T18:35:02.331139Z","shell.execute_reply":"2023-06-12T18:35:02.330174Z","shell.execute_reply.started":"2023-06-12T18:35:00.569092Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n","\n","\n","#######################\n","\n","\n","\n","train_set = torchvision.datasets.CIFAR10('./datasets', train=True, \n","                                         download=True, transform=transform)\n","test_set = torchvision.datasets.CIFAR10('./datasets', train=False, \n","                                        download=True, transform=transform)\n","# Number of subprocesses to use for data loading\n","num_workers = 1\n","# How many samples per batch to load\n","batch_size = 32\n","# Percentage of training set to use as validation\n","valid_size = 0.5\n","\n","num_test = len(test_set)\n","indices = list(range(num_test))\n","np.random.shuffle(indices)\n","split = int(np.floor(valid_size * num_test))\n","test_idx, valid_idx = indices[split:], indices[:split]\n","\n","# Define samplers for obtaining training and validation batches\n","test_sampler = SubsetRandomSampler(test_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","\n","# Prepare data loaders (combine dataset and sampler)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n","                                           num_workers=num_workers)\n","valid_loader = torch.utils.data.DataLoader(test_set, batch_size= 1, sampler=valid_sampler, \n","                                           num_workers=num_workers)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=2048, sampler=test_sampler, num_workers=num_workers)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:35:02.338054Z","iopub.status.busy":"2023-06-12T18:35:02.335755Z","iopub.status.idle":"2023-06-12T18:35:02.483187Z","shell.execute_reply":"2023-06-12T18:35:02.481555Z","shell.execute_reply.started":"2023-06-12T18:35:02.338020Z"},"trusted":true},"outputs":[],"source":["\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","\n","\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(valid_loader)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:35:02.491117Z","iopub.status.busy":"2023-06-12T18:35:02.488886Z","iopub.status.idle":"2023-06-12T18:35:02.500239Z","shell.execute_reply":"2023-06-12T18:35:02.499406Z","shell.execute_reply.started":"2023-06-12T18:35:02.491077Z"},"trusted":true},"outputs":[],"source":["\n","\n","def ten2mat(tensor):\n","    r,c,ch,f = tensor.shape\n","    new_dim = [c,r*ch*f]\n","    return np.reshape(tensor, new_dim)\n","\n","def eff_rank(matrix):\n","    frob = np.linalg.norm(matrix, 'fro')\n","    svals = svdvals(matrix)\n","    S = max(svals)\n","    r = frob/S\n","    return (r)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:35:02.507176Z","iopub.status.busy":"2023-06-12T18:35:02.504649Z","iopub.status.idle":"2023-06-12T18:35:02.591805Z","shell.execute_reply":"2023-06-12T18:35:02.590492Z","shell.execute_reply.started":"2023-06-12T18:35:02.507146Z"},"trusted":true},"outputs":[],"source":["\n","\n","#utility functions\n","\n","\n","#reshape weight/feature tensor into a matrix\n","def ten2mat(tensor):\n","    r,c,ch,f = tensor.shape\n","    new_dim = [c,r*ch*f]\n","    return np.reshape(tensor, new_dim)\n","################################################################################################################\n","#Compute stable rank\n","def eff_rank(matrix):\n","    frob = np.linalg.norm(matrix, 'fro')\n","    svals = svdvals(matrix)\n","    S = max(svals)\n","    r = frob/S\n","    return (r)\n","\n","################################################################################################################\n","\n","# a dict to store the activations\n","activation = {}\n","def getActivation(name):\n","  # the hook signature\n","    def hook(model, input, output):\n","        activation[name] = output.detach()\n","    return hook\n","\n","################################################################################################################\n","\n","#Function to get conv+bn feature means\n","def get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter):\n","    \n","    activation = {}\n","    def getActivation(name):\n","      # the hook signature\n","        def hook(model, input, output):\n","            activation[name] = output.detach()\n","        return hook\n","    \n","    mat_features_list_conv = [ [] ]*(nc*num_classes)\n","    mat_features_list_bn = [ [] ]*(nc*num_classes)\n","\n","    count = np.zeros((nc*num_classes))\n","\n","    #with torch.no_grad():\n","    for i in range(num_samples):\n","        \n","        try:\n","            image,label = next(dataiter)\n","        except StopIteration:\n","            dataiter = iter(train_loader)\n","            image,label = next(dataiter)\n","        \n","        \n","        l2 =label.detach().numpy()\n","        l2 = l2[0]\n","        #print(l2)\n","        for j in range(nc):#range(len(conv_dict)):\n","            activation = {}\n","            z1 = conv_dict[j]\n","            z2 = z1 + 1\n","\n","            #print(z1,z2)\n","            h1 = model.features[z1].register_forward_hook(getActivation('conv2d'))\n","            h2 = model.features[z2].register_forward_hook(getActivation('bn'))\n","\n","            output = model(image.to(device))\n","\n","            Xx1 = activation['conv2d']\n","            Xx2 = activation['bn']\n","\n","            Xx1 = Xx1.to(device = 'cpu')\n","            Xx2 = Xx2.to(device = 'cpu')\n","\n","            Xx01 = Xx1.detach().numpy()\n","            Xx02 = Xx2.detach().numpy()\n","\n","            temp_mat1 = ten2mat(Xx01)\n","            temp_mat2 = ten2mat(Xx02)\n","\n","            temp_idx = int(num_classes*j + l2)\n","\n","            count[temp_idx]+=1\n","            #print(i, np.linalg.norm(temp_mat1),np.linalg.norm(temp_mat2), np.linalg.norm(temp_mat3), l2, j, z1, temp_idx)\n","\n","            l31 = len(mat_features_list_conv[temp_idx])\n","            l32 = len(mat_features_list_bn[temp_idx])\n","\n","            if l31 == 0:\n","                mat_features_list_conv[temp_idx] = temp_mat1\n","\n","            else:\n","                mat_features_list_conv[temp_idx] = mat_features_list_conv[temp_idx] + temp_mat1\n","\n","            if l32 == 0:\n","                mat_features_list_bn[temp_idx] = temp_mat2\n","\n","            else:\n","                mat_features_list_bn[temp_idx] = mat_features_list_bn[temp_idx] + temp_mat2\n","\n","\n","            h1.remove()\n","            h2.remove()\n","       \n","    for i in range(nc*num_classes):\n","        mat_features_list_conv[i] = mat_features_list_conv[i] / count[i]\n","        mat_features_list_bn[i] = mat_features_list_bn[i] / count[i]\n","    \n","    return mat_features_list_conv, mat_features_list_bn, count\n","\n","\n","#################################################################################################################\n","\n","#function to get differences between features\n","\n","def get_features_diff(nc, num_classes, mat_features_list, conv_dict):\n","    \n","    mat_diff_list = []\n","    \n","    ll = int(0.5 * num_classes * (num_classes - 1))\n","\n","\n","    count_list = [ [[]]*ll ]*nc\n","\n","    for k in range(nc):\n","        idx1 = 0\n","        idx2 = num_classes*k\n","        temp_list = [[]]*ll\n","\n","        for i in range(num_classes):\n","            for j in range(i+1,num_classes):\n","                #print(idx1)\n","                ti = i+idx2\n","                tj = j+idx2\n","                temp1 = mat_features_list[ti] - mat_features_list[tj]\n","                \n","                temp_list[idx1] = temp1\n","\n","                count_list[k][idx1]= (i,j)\n","                idx1+=1\n","        mat_diff_list.append([temp_list])\n","\n","        \n","    return mat_diff_list\n","\n","#################################################################################################################\n","        \n","def get_min_list(nc, num_classes, mat_diff_list):\n","    min_list = []\n","    ll = int(0.5 * num_classes * (num_classes - 1))\n","\n","    for k in range(nc):\n","        layer_list = mat_diff_list[k][0]\n","\n","\n","        tempmat = layer_list[0]\n","        \n","        Y_conv = np.shape(tempmat)\n","        num_channels = Y_conv[0]\n","        #print(ll)\n","        temp_min_list= [[]]*num_channels\n","\n","\n","        for i in range(ll):\n","            temp1  = layer_list[i]\n","\n","\n","\n","            temp1n = np.linalg.norm(temp1, axis=1)\n","\n","\n","            for j in range(num_channels):           \n","                if bool(temp_min_list[j]):\n","                    if temp_min_list[j] > temp1n[j]:\n","                        temp_min_list[j] = temp1n[j]                    \n","                else:\n","                    temp_min_list[j] = temp1n[j]\n","\n","\n","\n","\n","        min_list.append(temp_min_list)\n","    return min_list\n","\n","\n","################################################################################################################\n","\n","def test(model, data_loader, device):\n","    acc = 0  # TODO compute top1\n","    correct_samples = 0\n","    total_samples = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for (idx, (x, t)) in enumerate(data_loader):\n","            x = model.forward(x.to(device))\n","            t = t.to(device)\n","            _, indices = torch.max(x, 1)\n","            correct_samples += torch.sum(indices == t)\n","            total_samples += t.shape[0]\n","\n","    acc = float(correct_samples) / total_samples\n","    return acc\n","\n","################################################################################################################\n","\n","def get_crit_vals(nc, min_list, crit_frac):\n","    minlist = []\n","    min_means = []\n","    min_crit = []\n","    for i in range(nc):\n","        temp_list = min_list[i] / np.max(min_list[i])\n","        mean = np.mean(temp_list)\n","\n","\n","        #print(i,mean_conv, mean_bn)\n","\n","        crit = crit_frac* mean\n","        minlist.append(np.min(temp_list))\n","        min_means.append(mean)\n","        min_crit.append(crit)\n","    \n","    return min_list, min_means, min_crit\n","\n","################################################################################################################\n","\n","def get_pruning_mask2(nc, min_crit, min_list,model, conv_dict):\n","    \n","    Mask = [[]]*nc\n","    filters_pruned = [[]]*nc\n","    filters_remain = [[]]*nc\n","    \n","    for k in range(nc):\n","\n","\n","                #Conv output\n","        Scores= min_list[k] \n","        Scores = Scores / np.max(Scores)\n","        len_sc = int(len(Scores))\n","\n","\n","        Criterion = min_crit[k]\n","        mask = np.ones(len_sc)\n","        for i in range(len(Scores)):\n","            temp = Scores[i]-Criterion\n","            if temp <= 0:\n","                mask[i]= 0\n","\n","                \n","        num_rem = int(np.sum(mask))\n","        num_prn = int(len(mask) - num_rem)  \n","        \n","        filters_pruned[k] = num_prn\n","        filters_remain[k] = num_rem\n","\n","        \n","        Test_ten = model.features[conv_dict[k]].weight\n","        \n","        Test_ten = Test_ten.to(device = 'cpu')\n","\n","        Test_ten = Test_ten.detach().numpy()\n","\n","        r,c,ch,f = np.shape(Test_ten)\n","        Test_Mask = [[]]*r\n","        One_ten = np.ones((c,ch,f))\n","        for i in range(r):\n","            Test_Mask[i] = One_ten*mask[i]\n","        X = torch.tensor(Test_Mask).to(device)\n","       \n","        \n","       \n","        \n","        Mask[k] = X\n","    return Mask, filters_pruned, filters_remain\n","\n","\n","#################################################################################################################\n","\n","def prune_with_mask(nc, model, X, conv_dict):\n","    \n","    for k in range(nc):\n","        mm = prune.custom_from_mask(model.features[conv_dict[k]], name='weight', mask=X)\n","    \n","    return model\n","\n","#################################################################################################################\n","def get_pruned_acc(nc, min_crit, min_list,model, conv_dict,test_loader,device):\n","    \n","    filters_pruned = [[]]*nc\n","    filters_remain = [[]]*nc\n","           \n","    for k in range(nc):\n","        #print(idx)\n","        \n","        \n","        #Conv output\n","        Scores = min_list[k] \n","        Scores = Scores / np.max(Scores)\n","        len_sc = int(len(Scores))\n","\n","\n","        Criterion = min_crit[k]\n","        mask = np.ones(len_sc)\n","        for i in range(len(Scores)):\n","            temp = Scores[i]-Criterion\n","            if temp <= 0:\n","                mask[i]= 0\n","\n","                \n","        num_rem = int(np.sum(mask))\n","        num_prn = int(len(mask) - num_rem)  \n","        \n","        filters_pruned[k] = num_prn\n","        filters_remain[k] = num_rem\n","\n","      \n","        \n","        \n","        \n","        Test_ten = model.features[conv_dict[k]].weight\n","        \n","        Test_ten = Test_ten.to(device = 'cpu')\n","\n","        Test_ten = Test_ten.detach().numpy()\n","\n","        r,c,ch,f = np.shape(Test_ten)\n","        Test_Mask = [[]]*r\n","        One_ten = np.ones((c,ch,f))\n","        for i in range(r):\n","            Test_Mask[i] = One_ten*mask[i]\n","        X = torch.tensor(Test_Mask).to(device)\n","       \n","        m1 = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=X)\n","        \n","        \n","        #print(model_accs1[k, idx])\n","        #print(k, crit_frac, num_pruned, pf, T1)\n","    \n","    #device = torch.device('cuda')\n","    \n","    T1 = test(model, test_loader,device)\n","    T1 = 100*T1\n","    \n","    return model, T1\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-12T18:35:02.600132Z","iopub.status.busy":"2023-06-12T18:35:02.597781Z","iopub.status.idle":"2023-06-12T18:37:59.462078Z","shell.execute_reply":"2023-06-12T18:37:59.460373Z","shell.execute_reply.started":"2023-06-12T18:35:02.600097Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n","Using cache found in /Users/riddhichatterjee/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","/var/folders/zx/mkn76r6n0ybg5lfrqrg2v0v40000gn/T/ipykernel_5377/4180631273.py:267: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1646756029501/work/torch/csrc/utils/tensor_new.cpp:210.)\n","  X = torch.tensor(Test_Mask).to(device)\n"]},{"name":"stdout","output_type":"stream","text":["0.5 0 70.86 9.193313953488373 90.80668604651163\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /Users/riddhichatterjee/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"]},{"name":"stdout","output_type":"stream","text":["0.5 1 70.42 12.609011627906977 87.39098837209302\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /Users/riddhichatterjee/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"]},{"name":"stdout","output_type":"stream","text":["0.5 2 70.46 14.716569767441861 85.28343023255815\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /Users/riddhichatterjee/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"]},{"name":"stdout","output_type":"stream","text":["0.5 3 69.84 16.024709302325583 83.97529069767441\n"]},{"ename":"ValueError","evalue":"operands could not be broadcast together with shapes (64,1024) (64,32768) ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m uu\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwhile\u001b[39;00m Crit_frac \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#print(uu)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     mat_features_list_conv, mat_features_list_bn, count \u001b[39m=\u001b[39m get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     diff_list_conv \u001b[39m=\u001b[39m get_features_diff(nc, num_classes, mat_features_list_conv, conv_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     diff_list_bn \u001b[39m=\u001b[39m get_features_diff(nc, num_classes, mat_features_list_bn, conv_dict)\n","\u001b[1;32m/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb Cell 9\u001b[0m in \u001b[0;36mget_mean_features\u001b[0;34m(nc, num_classes, num_samples, conv_dict, model, dataiter)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     mat_features_list_conv[temp_idx] \u001b[39m=\u001b[39m temp_mat1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     mat_features_list_conv[temp_idx] \u001b[39m=\u001b[39m mat_features_list_conv[temp_idx] \u001b[39m+\u001b[39;49m temp_mat1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mif\u001b[39;00m l32 \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/riddhichatterjee/SummerProject2023/TVSPrune/distpruning-cifar10-vgg11.ipynb#X11sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     mat_features_list_bn[temp_idx] \u001b[39m=\u001b[39m temp_mat2\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (64,1024) (64,32768) "]}],"source":["\n","\n","U = 60\n","\n","# accs = np.zeros(U)\n","\n","accs = []\n","\n","# num_pruned = np.zeros(U)\n","# num_remain = np.zeros(U)\n","\n","num_pruned = []\n","num_remain = []\n","\n","\n","# conv_dict = [0,3,7,10,14,17,20,24,27,30, 34, 37, 40]\n","conv_dict = [0,4,8,11,15,18,22,25]\n","# conv_dict = [0,3,7,10,14,17,20,23,27,30,33,36,40,43,46,49]\n","\n","nc = int(len(conv_dict))\n","num_classes = 10\n","num_samples = 1024\n","\n","fracs = [.99,.9,.8, .7, .65,.6,.5,.4,.3,.2,.1,0]\n","Crit_frac = .5\n","\n","threshold = 56.00\n","frac_count = 0\n","accuracy = 100000\n","uu=0\n","\n","while Crit_frac > 0:\n","    #print(uu)\n","    mat_features_list_conv, mat_features_list_bn, count = get_mean_features(nc, num_classes, num_samples, conv_dict, model, dataiter) \n","    diff_list_conv = get_features_diff(nc, num_classes, mat_features_list_conv, conv_dict)\n","    diff_list_bn = get_features_diff(nc, num_classes, mat_features_list_bn, conv_dict)\n","    min_list_conv = get_min_list(nc, num_classes, diff_list_conv)\n","    min_list_bn = get_min_list(nc, num_classes, diff_list_bn)\n","   \n","    minlist_bn, minmeans_bn, min_crit_bn = get_crit_vals(nc, min_list_bn, Crit_frac)\n","    \n","    test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg11_bn\", pretrained=True)\n","    #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg16_bn\", pretrained=True)\n","    #test_model1 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg11_bn\", pretrained=True)\n","\n","\n","    test_model1 = test_model1.to(device)\n","    \n","    Mask_bn, filters_pruned_bn, filters_remain_bn = get_pruning_mask2(nc, min_crit_bn, min_list_bn,test_model1, conv_dict)\n","    \n","#     num_pruned[uu] = np.sum(filters_pruned_bn)\n","#     num_remain[uu] = np.sum(filters_remain_bn)\n","    fpbn = np.sum(filters_pruned_bn)\n","    frbn = np.sum(filters_remain_bn)\n","    np.append(num_pruned, fpbn)\n","    np.append(num_remain, frbn)\n","    \n","    pf = 100 * (fpbn / (fpbn + frbn))\n","    \n","    for k in range(nc):\n","        mm = prune.custom_from_mask( test_model1.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n","        mm = prune.remove(mm, name='weight')\n","    \n","    T2 = test(test_model1, test_loader, device)\n","    accuracy = T2 * 100\n","    #accs[uu] = T2 *100\n","    np.append(accs,accuracy)\n","    \n","    if accuracy >= threshold:\n","        for k in range(nc):\n","            mmm = prune.custom_from_mask( model.features[conv_dict[k]], name='weight', mask=Mask_bn[k])\n","            mmm = prune.remove(mmm, name='weight')\n","            \n","        \n","        print(Crit_frac, uu, T2*100, pf, 100-pf)\n","    else:\n","        print(Crit_frac, uu, T2*100, pf, 100-pf)\n","        frac_count +=1\n","        Crit_frac = np.maximum(0, Crit_frac - 0.025)\n","        \n","    uu +=1\n","        \n","    \n","    \n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-06-12T18:37:59.464046Z","iopub.status.idle":"2023-06-12T18:37:59.465293Z","shell.execute_reply":"2023-06-12T18:37:59.465123Z","shell.execute_reply.started":"2023-06-12T18:37:59.465097Z"},"trusted":true},"outputs":[],"source":["\n","\n","a_file = open(\"test_vgg11_cifar100.txt\", \"a\")\n","\n","\n","np.savetxt(a_file, [filters_pruned_bn], fmt = '%1.1i')\n","\n","np.savetxt(a_file, [filters_remain_bn], fmt = '%1.1i')\n","\n","np.savetxt(a_file, [accuracy], fmt = '%1.4f')\n","\n","\n","a_file.close()\n","\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
